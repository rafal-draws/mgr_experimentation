{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b17ad5-da15-4888-a1c4-2ceb79593646",
   "metadata": {},
   "source": [
    "# Preparing data for training the models per one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6fa11a-a771-4e88-a5e4-153da4f6b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import librosa\n",
    "from notebook_utilities import *\n",
    "\n",
    "import_data_science(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3332cbc-6ecf-4bd8-8030-0f46219b791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: (1742,)\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(\"/\", \"mnt\", \"e\")\n",
    "artifacts = os.path.join(root, \"artifacts\")\n",
    "\n",
    "\n",
    "training_data = os.path.join(root, \"dev\", \"training_data\")\n",
    "\n",
    "# reading signal\n",
    "raw = pd.read_parquet(os.path.join(artifacts, 'signals_10s_1750tracks.parquet'))\n",
    "# raw = pd.read_parquet('G:\\\\artifacts\\\\signals2s7k.parquet')\n",
    "\n",
    "\n",
    "# assigning feature\n",
    "signals = raw['y']\n",
    "signals.shape\n",
    "\n",
    "\n",
    "# udf register\n",
    "one_hot_encoding = np.vectorize(data_transformation.one_hot_function)\n",
    "\n",
    "\n",
    "labels = raw['genre']\n",
    "\n",
    "# label assigning\n",
    "labels = one_hot_encoding(labels)\n",
    "print(f\"labels shape: {labels.shape}\")\n",
    "\n",
    "\n",
    "# from str, removing [] with [1:-1], splitting each float, making a np array from list, casting to float32 \n",
    "\n",
    "signals = signals.apply(lambda x: np.array(x[1:-1].split(','), dtype=np.float32))\n",
    "signals = signals.to_numpy()\n",
    "\n",
    "print(f\"signal shape {signals[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553507",
   "metadata": {},
   "source": [
    "# Splitting signal in frames with 1/2 frame hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "frames_amount = signals[1].shape[0] // 22050 \n",
    "\n",
    "[x*11025 for x in range(1, frames_amount * 2 + 1)]\n",
    "\n",
    "for signal, label in zip(signals, labels):\n",
    "    \n",
    "    for i in range(0, (frames_amount * 2)-1):\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "            X_train.append(signal[0:22050])\n",
    "            y_train.append(label)\n",
    "        else:\n",
    "\n",
    "            X_train.append(signal[i*11025:(i+2)*11025])\n",
    "            y_train.append(label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fcb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(X_train):\n",
    "    if i.shape[0] != 22050:\n",
    "        print(f\"idx: {idx} was faulty\")\n",
    "\n",
    "\n",
    "len(y_train), len(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc8599-f706-47dc-92cd-bbeafc19d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_make_numpy(x, y):\n",
    "    x = np.array(x).astype(np.float32)\n",
    "    y = np.array(y).astype(np.int32)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = normalize_and_make_numpy(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "x_waveform, y_waveform = x, y\n",
    "x_waveform.shape, y_waveform.shape, x_waveform[0].shape, y_waveform[0]\n",
    "\n",
    "\n",
    "with open(f\"{training_data}/labels.npy\", \"wb\") as f:\n",
    "    np.save(f, y_waveform)\n",
    "\n",
    "with open(f\"{training_data}/waveform.npy\", \"wb\") as f:\n",
    "    np.save(f, x_waveform)\n",
    "\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:\n",
    "    f.write(f\"x_waveform.shape={x_waveform.shape}\\n\")\n",
    "    f.write(f\"labels.shape={y_waveform.shape}\\n\")\n",
    "\n",
    "# del x_waveform\n",
    "# del y_waveform\n",
    "\n",
    "\n",
    "for signal, label in zip(x_waveform[:5], y_waveform[:5]):\n",
    "    print(f\"signal shape: {signal.shape[0]}, label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238b49d",
   "metadata": {},
   "source": [
    "# Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596af9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "ft = []\n",
    "ft_y = []\n",
    "pop = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        transformed = np.abs(librosa.stft(record, hop_length=256))\n",
    "        fin = time.time() - start\n",
    "        \n",
    "        transformation_time = np.append(transformation_time, fin)\n",
    "        \n",
    "    \n",
    "        if label == 3:\n",
    "            pop.append(transformed)\n",
    "            \n",
    "        ft.append(transformed)\n",
    "        ft_y.append(label)\n",
    "        op = time.time() - start\n",
    "    \n",
    "        op_time = np.append(op_time, op)\n",
    "    \n",
    "        print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    except:\n",
    "        print(\"Couldn't transform to fourier transform\")\n",
    "        \n",
    "ft = np.array(ft).astype(np.float32)\n",
    "ft_y = np.array(ft_y).astype(np.int32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "values, counts = np.unique(ft_y, return_counts=True)\n",
    "value_counts = dict(zip(values, counts))\n",
    "value_counts, ft.shape, ft_y.shape\n",
    "\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "\n",
    "with open(f\"{training_data}/ft.npy\", \"wb\") as f:\n",
    "    np.save(f, ft)\n",
    "\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:\n",
    "    f.write(f\"ft.shape={ft.shape}\\n\")\n",
    "\n",
    "# del ft\n",
    "# del ft_y\n",
    "value_counts, ft.shape, ft_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ft = np.array(pop).astype(np.float32)\n",
    "\n",
    "pop_ft.shape, pop_ft[0].shape\n",
    "\n",
    "for pop_signal in pop_ft:\n",
    "    print(f\"pop signal shape: {pop_signal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8a8f8",
   "metadata": {},
   "source": [
    "# Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_x = []\n",
    "spec_y = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        spec = librosa.amplitude_to_db(np.abs(librosa.stft(record, hop_length=256)), ref=np.max)\n",
    "        fin = time.time() - start\n",
    "        \n",
    "        transformation_time = np.append(transformation_time, fin)\n",
    "        \n",
    "        spec_x.append(transformed)\n",
    "        spec_y.append(label)\n",
    "        op = time.time() - start\n",
    "\n",
    "        op_time = np.append(op_time, op)\n",
    "\n",
    "        print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    except:\n",
    "        print(\"Couldn't extract spectogram\")\n",
    "        \n",
    "spec_x = np.array(spec_x).astype(np.float32)\n",
    "spec_y = np.array(spec_y).astype(np.int32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "with open(f\"{training_data}/spectogram.npy\", \"wb\") as f:\n",
    "    np.save(f, spec_x)\n",
    "\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:\n",
    "    f.write(f\"spectogram.shape={spec_x.shape}\\n\")\n",
    "\n",
    "del spec_x\n",
    "del spec_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6707f",
   "metadata": {},
   "source": [
    "# Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spec_x = []\n",
    "mel_spec_y = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        \n",
    "        mel_spect = librosa.feature.melspectrogram(y=record, sr=22050, n_fft=8192, hop_length=256, n_mels=1025)\n",
    "        mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "        \n",
    "        fin = time.time() - start\n",
    "        \n",
    "        transformation_time = np.append(transformation_time, fin)\n",
    "        \n",
    "        mel_spec_x.append(mel_spect)\n",
    "        mel_spec_y.append(label)\n",
    "        op = time.time() - start\n",
    "\n",
    "        op_time = np.append(op_time, op)\n",
    "\n",
    "        print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    except:\n",
    "        print(\"Couldn't extract mel spectrogram\")\n",
    "        \n",
    "mel_spec_x = np.array(mel_spec_x).astype(np.float32)\n",
    "mel_spec_y = np.array(mel_spec_y).astype(np.int32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "values, counts = np.unique(mel_spec_y, return_counts=True)\n",
    "value_counts = dict(zip(values, counts))\n",
    "value_counts, mel_spec_x.shape, mel_spec_y.shape\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/mel_spectogram.npy\", \"wb\") as f:\n",
    "    np.save(f, mel_spec_x)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:\n",
    "    f.write(f\"mel_spectogram.shape={mel_spec_x.shape}\\n\")\n",
    "\n",
    "del mel_spec_x\n",
    "del mel_spec_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89069bee",
   "metadata": {},
   "source": [
    "# Power Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66cf110",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spec_x = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        \n",
    "        ft = librosa.stft(record, hop_length=256)\n",
    "        power_spec = np.abs(ft) ** 2\n",
    "\n",
    "        # zamiana na skalę dB (logarytmiczna skala mocy)\n",
    "        # S_db = 10 * log10(S/ref)\n",
    "        # S to moc, ref to wartość odniesienia, np.max(S) to największa moc w całym spektogramie\n",
    "        power_db = librosa.power_to_db(power_spec, ref=np.max)\n",
    "\n",
    "        fin = time.time() - start\n",
    "        \n",
    "        transformation_time = np.append(transformation_time, fin)\n",
    "        \n",
    "        power_spec_x.append(power_db)\n",
    "        op = time.time() - start\n",
    "\n",
    "        op_time = np.append(op_time, op)\n",
    "\n",
    "        print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    except:\n",
    "        print(\"Couldn't extract power spectrogram\")\n",
    "        \n",
    "power_spec_x = np.array(power_spec_x).astype(np.float32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/power_spectogram.npy\", \"wb\") as f:\n",
    "    np.save(f, power_spec_x)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:   \n",
    "    f.write(f\"power_spectogram.shape={power_spec_x.shape}\\n\")\n",
    "\n",
    "del power_spec_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d79b6c",
   "metadata": {},
   "source": [
    "# MFCC (Mel Frequency Cepstral Coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    try:\n",
    "            \n",
    "        mfcc_x = librosa.feature.mfcc(y=record, sr=22050, n_mfcc=12, hop_length=256)\n",
    "\n",
    "        fin = time.time() - start\n",
    "        \n",
    "        transformation_time = np.append(transformation_time, fin)\n",
    "        \n",
    "        mfcc.append(mfcc_x)\n",
    "        op = time.time() - start\n",
    "\n",
    "        op_time = np.append(op_time, op)\n",
    "\n",
    "        print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    except:\n",
    "        print(\"Couldn't calculate MFCC\")\n",
    "        \n",
    "mfcc = np.array(mfcc).astype(np.float32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/mfcc.npy\", \"wb\") as f:\n",
    "    np.save(f, mfcc)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:   \n",
    "    f.write(f\"mfcc.shape={mfcc.shape}\\n\")\n",
    "\n",
    "# del mfcc\n",
    "# del mfcc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b17fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "    stft.shape:         {ft.shape}\n",
    "    spec.shape:         {spec.shape}\n",
    "    mel_spec.shape:     {mel_spect.shape}\n",
    "    powerspect.shape:   {power_spec.shape}\n",
    "    mfcc.shape:         {mfcc.shape}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b00f245",
   "metadata": {},
   "source": [
    "# Chroma features (cechy chromatyczne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    try:\n",
    "            \n",
    "        chroma_x = librosa.feature.chroma_stft(y=record, sr=22050, n_chroma=12, hop_length=256, n_fft=2048)\n",
    "\n",
    "        fin = time.time() - start\n",
    "        \n",
    "        transformation_time = np.append(transformation_time, fin)\n",
    "        \n",
    "        chroma.append(chroma_x)\n",
    "        op = time.time() - start\n",
    "\n",
    "        op_time = np.append(op_time, op)\n",
    "\n",
    "        print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    except:\n",
    "        print(f\"Couldn't calculate Chroma features for signal {idx}\")\n",
    "        \n",
    "chroma = np.array(chroma).astype(np.float32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/chroma_stft.npy\", \"wb\") as f:\n",
    "    np.save(f, chroma)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:   \n",
    "    f.write(f\"chroma_stft.shape={chroma.shape}\\n\")\n",
    "\n",
    "# del mfcc\n",
    "# del mfcc_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ae5ab",
   "metadata": {},
   "source": [
    "# Chroma CQT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1390bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    # try:\n",
    "            \n",
    "    chroma_cqt_x = librosa.feature.chroma_cqt(y=record, sr=22050, n_chroma=12, hop_length=512)\n",
    "\n",
    "    fin = time.time() - start\n",
    "    \n",
    "    transformation_time = np.append(transformation_time, fin)\n",
    "    \n",
    "    chroma.append(chroma_cqt_x)\n",
    "    op = time.time() - start\n",
    "\n",
    "    op_time = np.append(op_time, op)\n",
    "\n",
    "    print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    # except:\n",
    "    #     print(f\"Couldn't calculate Chroma features for signal {idx}\")\n",
    "        \n",
    "chroma = np.array(chroma).astype(np.float32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/chroma_cqt.npy\", \"wb\") as f:\n",
    "    np.save(f, chroma)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:   \n",
    "    f.write(f\"chroma_cqt.shape={chroma.shape}\\n\")\n",
    "\n",
    "# del mfcc\n",
    "# del mfcc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(chroma[0], x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Chroma CENS')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "chroma[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    # try:\n",
    "            \n",
    "    chroma_cens_x = librosa.feature.chroma_cens(y=record, sr=22050, n_chroma=12, hop_length=512)\n",
    "\n",
    "    fin = time.time() - start\n",
    "    \n",
    "    transformation_time = np.append(transformation_time, fin)\n",
    "    \n",
    "    chroma.append(chroma_cens_x)\n",
    "    op = time.time() - start\n",
    "\n",
    "    op_time = np.append(op_time, op)\n",
    "\n",
    "    print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    # except:\n",
    "    #     print(f\"Couldn't calculate Chroma features for signal {idx}\")\n",
    "        \n",
    "chroma = np.array(chroma).astype(np.float32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/chroma_cens.npy\", \"wb\") as f:\n",
    "    np.save(f, chroma)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:   \n",
    "    f.write(f\"chroma_cens.shape={chroma.shape}\\n\")\n",
    "\n",
    "# del mfcc\n",
    "# del mfcc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(chroma[0], x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Chroma CENS')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "chroma[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002b4f4",
   "metadata": {},
   "source": [
    "# Tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "tonnetz_arr = []\n",
    "\n",
    "transformation_time = np.array([])\n",
    "op_time = np.array([])\n",
    "\n",
    "\n",
    "for idx, (record, label) in enumerate(zip(x,y)):\n",
    "    start = time.time()\n",
    "    # try:\n",
    "                \n",
    "    chroma = librosa.feature.chroma_cqt(y=record, sr=22050)\n",
    "    tonnetz = librosa.feature.tonnetz(chroma=chroma, sr=22050)\n",
    "    fin = time.time() - start\n",
    "    \n",
    "    transformation_time = np.training_data(transformation_time, fin)\n",
    "    \n",
    "    tonnetz_arr.append(tonnetz)\n",
    "    op = time.time() - start\n",
    "\n",
    "    op_time = np.append(op_time, op)\n",
    "\n",
    "    print(f\"{(idx/x.shape[0])*100:.2f}%\")\n",
    "\n",
    "    # except:\n",
    "    #     print(f\"Couldn't calculate Chroma features for signal {idx}\")\n",
    "        \n",
    "tonnetz_arr = np.array(tonnetz_arr).astype(np.float32)\n",
    "\n",
    "print(f\"mean transformation time: {transformation_time.mean():.4f}s\")\n",
    "print(f\"mean operation time: {op_time.mean():.4f}s\")\n",
    "\n",
    "\n",
    "# ft.to_parquet(f'G:\\\\dev\\\\ft.parquet',\n",
    "#             engine=\"fastparquet\", compression=\"snappy\")\n",
    "\n",
    "with open(f\"{training_data}/tonnetz.npy\", \"wb\") as f:\n",
    "    np.save(f, tonnetz_arr)\n",
    "with open(f\"{training_data}/metadata\", \"a\") as f:   \n",
    "    f.write(f\"chroma_cens.shape={tonnetz_arr.shape}\\n\")\n",
    "\n",
    "# del mfcc\n",
    "# del mfcc_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
